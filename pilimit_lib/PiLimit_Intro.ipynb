{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XaxbsdpwLd5V",
        "y80WkLsNRilM",
        "6vgDTGuORxkj"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "928051f89a10421b80101725763829f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e934ff86add542dab5975944226a6dff",
              "IPY_MODEL_3845ae94aba94a0c92d89c8b032747b9",
              "IPY_MODEL_1d35e4c278614aa9a65d65d522b4c0e7"
            ],
            "layout": "IPY_MODEL_2fb30ac431df4fe59c55ef2209da561a"
          }
        },
        "e934ff86add542dab5975944226a6dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc78ce0bac1f40aeb138cd9603b665ff",
            "placeholder": "​",
            "style": "IPY_MODEL_dba204eb09524b07ae2fe78b5e12778c",
            "value": "100%"
          }
        },
        "3845ae94aba94a0c92d89c8b032747b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9e35f9bce60436ab430d273b7d67c03",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef47e13fd9c34747a6e18ab822832926",
            "value": 170498071
          }
        },
        "1d35e4c278614aa9a65d65d522b4c0e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f143cae07bb4803b8a40e5f741df9c2",
            "placeholder": "​",
            "style": "IPY_MODEL_2c902b3bb95549f5bfa5160b9ce4a45e",
            "value": " 170498071/170498071 [00:02&lt;00:00, 68895669.18it/s]"
          }
        },
        "2fb30ac431df4fe59c55ef2209da561a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc78ce0bac1f40aeb138cd9603b665ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dba204eb09524b07ae2fe78b5e12778c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9e35f9bce60436ab430d273b7d67c03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef47e13fd9c34747a6e18ab822832926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f143cae07bb4803b8a40e5f741df9c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c902b3bb95549f5bfa5160b9ce4a45e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Efficient Computation of Deep Nonlinear Infinite-Width Neural Networks that Learn Features**\n",
        "\n",
        "Welcome to the tutorial for using the Pi-Limit Python library, based on our work [published in ICLR 2022](https://openreview.net/pdf?id=tUMr0Iox8XW). Using this library, one can easily create their own trainable pi-nets.\n",
        "\n",
        "In this notebook, we will walk through:\n",
        "- Creating a basic infinite-width Pi-MLP\n",
        "- Training it on some dummy data\n",
        "- Training the network on CIFAR10\n",
        "- Saving & reloading a trained network\n",
        "- Sampling a finite Pi-Net and testing its performance\n",
        "\n",
        "We will create a basic infinite-width Pi-MLP, first train it on some dummy data, and then train it on CIFAR10. Let's first begin by downloading the pip package for pilimit.\n"
      ],
      "metadata": {
        "id": "mnajuqBG_Y7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation\n",
        "\n",
        "Please use the following commands to install the pilimit library (includes some extra commands for this Colab notebook - the main command is the pip install from the git repo)."
      ],
      "metadata": {
        "id": "XaxbsdpwLd5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --upgrade setuptools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka93Fy86K2dL",
        "outputId": "79d8afad-b2ed-4852-8c73-4eb046d01498"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (22.0.4)\n",
            "Collecting pip\n",
            "  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.4\n",
            "    Uninstalling pip-22.0.4:\n",
            "      Successfully uninstalled pip-22.0.4\n",
            "Successfully installed pip-23.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (63.4.3)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-67.6.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 63.4.3\n",
            "    Uninstalling setuptools-63.4.3:\n",
            "      Successfully uninstalled setuptools-63.4.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "cvxpy 1.3.0 requires setuptools<=64.0.2, but you have setuptools 67.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-67.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGq-u6p__YGW",
        "outputId": "0e06945c-5b7c-4a88-81d5-583db4c9179d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping pilimit as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pilimit\n",
            "  Cloning https://github.com/santacml/pilim.git to /tmp/pip-install-tvysssl9/pilimit_ea16e011287a471285d196cd98d1afef\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/santacml/pilim.git /tmp/pip-install-tvysssl9/pilimit_ea16e011287a471285d196cd98d1afef\n",
            "  Resolved https://github.com/santacml/pilim.git to commit 84968cc2046fb3c754e27230b68528c8f51f0276\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pilimit) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from pilimit) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from pilimit) (0.14.1+cu116)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.9/dist-packages (from pilimit) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.12.0->pilimit) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision->pilimit) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->pilimit) (8.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->pilimit) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->pilimit) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->pilimit) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->pilimit) (2.0.12)\n",
            "Building wheels for collected packages: pilimit\n",
            "  Building wheel for pilimit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pilimit: filename=pilimit-0.1.0-py3-none-any.whl size=140585 sha256=8afcc51dd62f6b6f8600b34608990cbb9cebd0c8ef2e896e658ee874097c404e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w4gbm89h/wheels/63/9f/89/2e5302a7b80ab2280ef99317355f63d2cee8fa521516567afd\n",
            "Successfully built pilimit\n",
            "Installing collected packages: pilimit\n",
            "Successfully installed pilimit-0.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip uninstall pilimit -y\n",
        "!pip install  git+https://github.com/santacml/pilim.git#egg=pilimit "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a basic Pi-Net"
      ],
      "metadata": {
        "id": "5paljUajLhrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inside the package pilimit_lib, we provide torch-style infinite-width fully connected layers for use in networks. These layers can be used to easily create a network using familiar torch syntax. \n",
        "\n",
        "Examples are provided in examples.networks which are already good to go. Let's quickly go through a standard infinite MLP as defined in the networks file (edited for this notebook).\n",
        "\n",
        "Feel free to copy and use this network for other projects. However, our intention is to provide easy-to-use primitives which others may easily build upon.\n"
      ],
      "metadata": {
        "id": "07v2vZt0Bf83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from pilimit_lib.inf.layers import InfPiInputLinearReLU, InfPiLinearReLU\n",
        "from pilimit_lib.examples.networks import PiNet\n",
        "\n",
        "\n",
        "class InfMLP(PiNet):\n",
        "    def __init__(\n",
        "            self, \n",
        "            d_in, \n",
        "            d_out, \n",
        "            r, \n",
        "            L, \n",
        "            first_layer_alpha=1, \n",
        "            last_layer_alpha=1, \n",
        "            bias_alpha=1, \n",
        "            last_bias_alpha=None, \n",
        "            layernorm=False, \n",
        "            cuda_batch_size=None, \n",
        "            device=\"cpu\"):\n",
        "        super(InfMLP, self).__init__()\n",
        "\n",
        "        self.d_in = d_in\n",
        "        self.d_out = d_out\n",
        "        self.r = r\n",
        "        self.L = L\n",
        "\n",
        "        # save as buffers for saving\n",
        "        self.register_buffer(\"first_layer_alpha\", torch.tensor(first_layer_alpha, dtype=torch.get_default_dtype()))\n",
        "        self.register_buffer(\"last_layer_alpha\", torch.tensor(last_layer_alpha, dtype=torch.get_default_dtype()))\n",
        "        self.register_buffer(\"bias_alpha\", torch.tensor(bias_alpha, dtype=torch.get_default_dtype()))\n",
        "        if last_bias_alpha is None:\n",
        "            last_bias_alpha = bias_alpha\n",
        "        self.register_buffer(\"last_bias_alpha\", torch.tensor(last_bias_alpha, dtype=torch.get_default_dtype()))\n",
        "        self.layernorm = layernorm\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        self.layers.append(InfPiInputLinearReLU(d_in, r, bias_alpha=bias_alpha, device=device))\n",
        "        for n in range(1, L+1):\n",
        "            self.layers.append(InfPiLinearReLU(r, device=device, bias_alpha=bias_alpha, layernorm=layernorm, cuda_batch_size=cuda_batch_size))\n",
        "        \n",
        "        self.layers.append(InfPiLinearReLU(r, r_out=d_out, output_layer=True, bias_alpha=last_bias_alpha, device=device, layernorm=layernorm, cuda_batch_size=cuda_batch_size))\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        for n in range(0, self.L+2):\n",
        "            x = self.layers[n](x)\n",
        "            if n == 0: \n",
        "                x *= self.first_layer_alpha\n",
        "            if n == self.L+1: \n",
        "                x *= self.last_layer_alpha\n",
        "        return x\n",
        "        "
      ],
      "metadata": {
        "id": "z-Lwxu3JCOWW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code should look generally familiar to anyone who has created a network in torch before. There are a few key things to note:\n",
        "\n",
        "\n",
        "\n",
        "1.   The network inherits from a class ```PiNet```; this is not strictly necessary, but ```PiNet``` simply helps with loading from a saved model. One could instead inherit from ```torch.nn.Module``` if so desired.\n",
        "\n",
        "2.   There is a special ```InfPiInputLinearReLU``` specifically for input layers due to the definition of the infinite width limit. These layers have a different formulation than middle layers.\n",
        "\n",
        "3. The general-purpose layer is ```InfPiLinearReLU```. As with the input layer, one can note that ReLU is baked-in to the layer and the activation cannot be changed. Again due to the formulation of the limit, this is necessary. We plan to add support for other activations in the future.\n",
        "\n",
        "With these core building blocks, one can easily create a Pi-Net.\n"
      ],
      "metadata": {
        "id": "DUJ7Qy1iDrDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What's in a layer?"
      ],
      "metadata": {
        "id": "5H4vZ4zZphwE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A layer like `InfPiLinearReLU` has 3 parameters which can be though of as 'trainable weights' - though, they differ from weights in the traditional sense. These parameters are:\n",
        "\n",
        "- A - represents the *post-activation portion* of the loss gradient from previous iterations\n",
        "- B - represents the *pre-activation portion* of the loss gradient from previous iterations\n",
        "- Amult - represents the accumulated learning rate and weight decay from previous iterations\n",
        "\n",
        "A and B function together to represent coefficients which would multiply and sum *r* (rank hyperparameter) gaussian vectors together. These matrices are of shape *m* by *r*, where *m* actually *grows* throughout training. For further explanation and details, please see our original work and blog post.\n"
      ],
      "metadata": {
        "id": "R6Kuk11Ipmrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training on dummy data"
      ],
      "metadata": {
        "id": "NG0ReJ2OMKDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's define some dummy data (just a sine wave) and train on it with the PiNet to see what a minimal training loop looks like. "
      ],
      "metadata": {
        "id": "gey7DVi1MT-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import time \n",
        "\n",
        "torch.manual_seed(3133)\n",
        "np.random.seed(3331)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "data = torch.linspace(-np.pi, np.pi, 100, device=device).reshape(-1, 1)\n",
        "labels = torch.sin(data) #.reshape(-1)\n",
        "data = torch.cat([data, torch.ones_like(data, device=device)], dim=1)"
      ],
      "metadata": {
        "id": "tMcCnf89MJcf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we create an instance of the earlier defined InfMLP."
      ],
      "metadata": {
        "id": "_YpAv2ORMfqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_in = 2\n",
        "d_out = 3\n",
        "r = 20\n",
        "L = 1\n",
        "bias_alpha = .5\n",
        "batch_size = 50\n",
        "net = InfMLP(d_in, d_out, r, L, device=device, bias_alpha=bias_alpha )"
      ],
      "metadata": {
        "id": "NJMd4a10MawF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's go through the core training loop. \n",
        "\n",
        "Again, this should look very familiar to anyone who has worked in PyTorch before. There are a few key differences which are listed below."
      ],
      "metadata": {
        "id": "rQIjWvSSnOQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pilimit_lib.inf.optim import PiSGD, store_pi_grad_norm_, clip_grad_norm_\n",
        "import sys\n",
        "\n",
        "net.train()\n",
        "epoch = 20\n",
        "accum_steps = 1\n",
        "gclip = .1\n",
        "optimizer = PiSGD(net.parameters(), lr = .02)\n",
        "tic = time.time()\n",
        "for epoch in range(epoch):\n",
        "    if epoch % accum_steps == 0:\n",
        "        optimizer.zero_grad()\n",
        "        net.zero_grad()\n",
        "    \n",
        "    prediction = net(data)\n",
        "    \n",
        "    loss = torch.sum((prediction - labels)**2)**.5\n",
        "\n",
        "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
        "    \n",
        "    loss.backward()\n",
        "    # stage_grad(net)\n",
        "\n",
        "    if epoch % accum_steps == 0:\n",
        "        # unstage_grad(net)\n",
        "\n",
        "        if gclip:\n",
        "            store_pi_grad_norm_(net.modules())\n",
        "            clip_grad_norm_(net.parameters(), gclip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    #print(\"Memory used\", torch.cuda.memory_reserved() / 1e9, torch.cuda.max_memory_reserved()  / 1e9)\n",
        "    print(\"Network A size\", net.layers[1].A.shape[0])\n",
        "print(\"time\", time.time() - tic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB8x0DMHMmym",
        "outputId": "0a35dba7-1209-4ca3-cb67-32638fdcfa2a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train loss: 12.186058044433594\n",
            "Network A size 120\n",
            "Epoch 1: train loss: 12.177803993225098\n",
            "Network A size 220\n",
            "Epoch 2: train loss: 12.16955852508545\n",
            "Network A size 320\n",
            "Epoch 3: train loss: 12.161317825317383\n",
            "Network A size 420\n",
            "Epoch 4: train loss: 12.153082847595215\n",
            "Network A size 520\n",
            "Epoch 5: train loss: 12.14484977722168\n",
            "Network A size 620\n",
            "Epoch 6: train loss: 12.13662052154541\n",
            "Network A size 720\n",
            "Epoch 7: train loss: 12.12839126586914\n",
            "Network A size 820\n",
            "Epoch 8: train loss: 12.120162010192871\n",
            "Network A size 920\n",
            "Epoch 9: train loss: 12.111932754516602\n",
            "Network A size 1020\n",
            "Epoch 10: train loss: 12.103699684143066\n",
            "Network A size 1120\n",
            "Epoch 11: train loss: 12.095463752746582\n",
            "Network A size 1220\n",
            "Epoch 12: train loss: 12.087224006652832\n",
            "Network A size 1320\n",
            "Epoch 13: train loss: 12.078978538513184\n",
            "Network A size 1420\n",
            "Epoch 14: train loss: 12.070727348327637\n",
            "Network A size 1520\n",
            "Epoch 15: train loss: 12.062467575073242\n",
            "Network A size 1620\n",
            "Epoch 16: train loss: 12.05419921875\n",
            "Network A size 1720\n",
            "Epoch 17: train loss: 12.04592227935791\n",
            "Network A size 1820\n",
            "Epoch 18: train loss: 12.03763484954834\n",
            "Network A size 1920\n",
            "Epoch 19: train loss: 12.029336929321289\n",
            "Network A size 2020\n",
            "time 0.26438474655151367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance doesn't really matter here; we want to take a look at what the code looks like when training a Pi-Net.\n",
        "\n",
        "Note that as we train, the size of an A matrix in the network also grows per training step. This is an important and unfortunate side effect of the inf-width limit. Using these models takes careful consideration of this growing memory requirement - the more memory that you can use, the better.\n",
        "\n",
        "Our library keeps as many native torch functions and syntax as possible, however, some drop-in replacement functions had to be created. These can be seen above. Here are the important ones:\n",
        "\n",
        "1.   ```PiSGD``` is the optimizer - regular torch optimizers will not work\n",
        "\n",
        "2.   ```store_pi_grad_norm_``` and ```clip_grad_norm_``` together allow for gradient clipping. It's necessary to use these two functions together as shown, given the unique format of the layers\n",
        "\n",
        "3. ```stage_grad``` and ```unstage_grad``` allow for gradient accumulation if desired (commented out here). It's again necessary to use both of these functions exactly as shown, due to the growing nature of the network.\n",
        "\n",
        "With these small caveats, the core training loop is largely the same!\n"
      ],
      "metadata": {
        "id": "4tEvXGkfQMy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training on (a small subsample of) CIFAR10"
      ],
      "metadata": {
        "id": "xbbLcAzyRJoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now train an example Pi-Net on CIFAR10. First, we download the dataset as normal.\n",
        "\n",
        "**NOTE**: given the restrictions of this colab notebook, we will take a subsample of 10 input samples of cifar10. Please download this notebook to run on a GPU-equipped computer to train fully."
      ],
      "metadata": {
        "id": "vehfl--IRLoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# standard cifar10 download code\n",
        "from torchvision import datasets, transforms\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "total_samples = 10\n",
        "batch_size = 1\n",
        "\n",
        "transform_list = []\n",
        "transform_list.extend([transforms.ToTensor()])\n",
        "\n",
        "transform_list.extend([transforms.Normalize([0.49137255, 0.48235294, 0.44666667], [0.24705882, 0.24352941, 0.26156863])])\n",
        "transform = transforms.Compose(transform_list)\n",
        "\n",
        "trainset = datasets.CIFAR10(root=\".\", train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "np.random.seed(0) # reproducability of subset\n",
        "indices = np.random.choice(range(50000), size=total_samples, replace=False).tolist()\n",
        "trainset = data_utils.Subset(trainset, indices)\n",
        "print(\"Using subset of\", len(trainset), \"training samples\")\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=False, num_workers=0)\n",
        "\n",
        "testset = datasets.CIFAR10(root=\".\", train=False,\n",
        "                                      download=True, transform=transform)\n",
        "np.random.seed(0) # reproducability of subset\n",
        "indices = np.random.choice(range(50000), size=total_samples, replace=False).tolist()\n",
        "testset = data_utils.Subset(testset, indices)\n",
        "print(\"Using subset of\", len(testset), \"testing samples\")\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                        shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "928051f89a10421b80101725763829f8",
            "e934ff86add542dab5975944226a6dff",
            "3845ae94aba94a0c92d89c8b032747b9",
            "1d35e4c278614aa9a65d65d522b4c0e7",
            "2fb30ac431df4fe59c55ef2209da561a",
            "bc78ce0bac1f40aeb138cd9603b665ff",
            "dba204eb09524b07ae2fe78b5e12778c",
            "b9e35f9bce60436ab430d273b7d67c03",
            "ef47e13fd9c34747a6e18ab822832926",
            "3f143cae07bb4803b8a40e5f741df9c2",
            "2c902b3bb95549f5bfa5160b9ce4a45e"
          ]
        },
        "id": "pxLAW208ROLr",
        "outputId": "165de93c-7a06-4c4b-be0c-c2c178c3f184"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "928051f89a10421b80101725763829f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n",
            "Using subset of 10 training samples\n",
            "Files already downloaded and verified\n",
            "Using subset of 10 testing samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we again define our InfMLP, along with a few basic hyperparameters.\n"
      ],
      "metadata": {
        "id": "jYcz7bJ_o2q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "d_in = 32*32*3\n",
        "d_out = 10\n",
        "r = 200\n",
        "epoch = 50\n",
        "L = 1 \n",
        "layernorm = False\n",
        "net = InfMLP(d_in, d_out, r, L, device=device, bias_alpha=bias_alpha, layernorm=layernorm)\n",
        "\n",
        "\n",
        "epoch = 100\n",
        "lr = .001\n",
        "gclip = 0\n",
        "# wd=0\n",
        "gclip = 0.5\n",
        "wd=0.1\n",
        "gclip_per_param = True\n",
        "step = True\n",
        "\n",
        "no_apply_lr_mult_to_wd = True\n",
        "\n",
        "first_layer_lr_mult = 1\n",
        "last_layer_lr_mult = 1\n",
        "bias_lr_mult = .1\n",
        "first_layer_alpha = 1\n",
        "bias_alpha = 1\n",
        "last_layer_alpha = 1"
      ],
      "metadata": {
        "id": "0gnxPy3BRZ7e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is some intentionally verbose code for demonstration. It would be entirely possible to simply use ``` net.parameters() ``` as normal to gather the network parameters, but if one wishes to use layer-specific LR or apply weight decay, the following syntax is necessary.\n",
        "\n",
        "Note the following:\n",
        "\n",
        "1.   Layer 0 is special - there is no Amult or B, and A gets a learning rate\n",
        "2.   After layer 0, only Amult gets learning rate/weight decay, but A and B are still added to optimizer\n",
        "  - Don't worry about configuring whether A and B get learning rate - this is all handled in the backend\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dPhtCOKzo5Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "paramgroups = []\n",
        "# first layer weights\n",
        "paramgroups.append({\n",
        "  'params': [net.layers[0].A],\n",
        "  'lr': first_layer_lr_mult * lr,\n",
        "  'weight_decay': wd / first_layer_lr_mult if no_apply_lr_mult_to_wd else wd\n",
        "})\n",
        "if net.layers[0].bias is not None:\n",
        "  paramgroups.append({\n",
        "    'params': [l.bias for l in net.layers],\n",
        "    'lr': bias_lr_mult * lr,\n",
        "    'weight_decay': wd / bias_lr_mult if no_apply_lr_mult_to_wd else wd\n",
        "  })\n",
        "paramgroups.append({\n",
        "  'params': [l.Amult for l in net.layers[1:-1]],\n",
        "})\n",
        "paramgroups.append({\n",
        "  'params': [net.layers[-1].Amult],\n",
        "  'lr': last_layer_lr_mult * lr,\n",
        "  'weight_decay': wd / last_layer_lr_mult if no_apply_lr_mult_to_wd else wd\n",
        "})\n",
        "paramgroups.append({\n",
        "  'params': [l.A for l in net.layers[1:]],\n",
        "})\n",
        "paramgroups.append({\n",
        "  'params': [l.B for l in net.layers[1:]],\n",
        "})\n",
        "optimizer = PiSGD(paramgroups, lr = lr, weight_decay=wd)\n",
        "\n",
        "# this is the easy way to get parameters \n",
        "# optimizer = PiSGD(net.parameters(), lr = lr, weight_decay=wd) "
      ],
      "metadata": {
        "id": "J4WV5UM1pFIv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can train on cifar10 using a core training loop very similar to the one above.\n",
        "\n",
        "Here is a very short example, only training for 10 \"epochs\" on a very small subset of samples."
      ],
      "metadata": {
        "id": "hxo30m7xqCNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.nn.functional as F\n",
        "  \n",
        "\n",
        "net.train()\n",
        "losses = []\n",
        "for epoch in range(epoch):\n",
        "  epoch_losses = []\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device).type(torch.get_default_dtype()), target.to(device)\n",
        "    data = data.reshape(data.shape[0], -1)\n",
        "    labels = target\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    net.zero_grad()\n",
        "    \n",
        "    prediction = net(data)\n",
        "    \n",
        "    oh_target = target.new_zeros(target.shape[0], 10).type(torch.get_default_dtype())\n",
        "    oh_target.scatter_(1, target.unsqueeze(-1), 1)\n",
        "    oh_target -= 0.1\n",
        "    loss = F.mse_loss(prediction, oh_target, reduction=\"mean\")\n",
        "      \n",
        "    loss.backward()\n",
        "\n",
        "    if gclip:\n",
        "        store_pi_grad_norm_(net.modules())\n",
        "        if gclip_per_param:\n",
        "          for param in net.parameters():\n",
        "              clip_grad_norm_(param, gclip)\n",
        "        else:\n",
        "          clip_grad_norm_(net.parameters(), gclip)\n",
        "\n",
        "    if step: optimizer.step()\n",
        "\n",
        "    epoch_losses.append(loss)\n",
        "\n",
        "  \n",
        "  if epoch % 10 == 0: \n",
        "    print('Epoch {}: train loss: {}'.format(epoch, (sum(epoch_losses) / len(epoch_losses)).item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XwWgewBSVwI",
        "outputId": "a5ba3bc3-fb5c-4ceb-a141-53708146ef03"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train loss: 0.09023816883563995\n",
            "Epoch 10: train loss: 0.08447568118572235\n",
            "Epoch 20: train loss: 0.08399686962366104\n",
            "Epoch 30: train loss: 0.08405115455389023\n",
            "Epoch 40: train loss: 0.08403242379426956\n",
            "Epoch 50: train loss: 0.08391579240560532\n",
            "Epoch 60: train loss: 0.08373766392469406\n",
            "Epoch 70: train loss: 0.08352664113044739\n",
            "Epoch 80: train loss: 0.08329982310533524\n",
            "Epoch 90: train loss: 0.08306676894426346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reloading a trained Infinite Pi-Net"
      ],
      "metadata": {
        "id": "NDytvhEIRakp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the main advantages of pilimit_lib is utilizing familiar torch-style syntax. We have one of our best Pi-Nets already trained on CIFAR10 available for download and use here: https://1drv.ms/u/s!Aqm-bcw66kwDnSYUPdFw-km20Hta?e=OrujuC\n",
        "\n",
        "In the following code block, we demonstrate loading an infinite pi-net and testing it on CIFAR10. Note **this notebook does not download the trained network** - Colab is not powerful enough. To test the net, download the above link and this notebook on a computer with a good GPU. Then, insert the path to the path variable and uncomment the commented lines.\n",
        "\n",
        "As-is, the code will produce only 10% accuracy, for random guessing."
      ],
      "metadata": {
        "id": "u28ZRqw01V5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "testset = datasets.CIFAR10(root=\".\", train=False,\n",
        "                                      download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                        shuffle=False, num_workers=0)\n",
        "\n",
        "d_in = 32*32*3\n",
        "d_out = 10\n",
        "r = 400\n",
        "L = 1\n",
        "layernorm = False\n",
        "net = InfMLP(d_in, d_out, r, L, device=device, bias_alpha=bias_alpha, layernorm=layernorm)\n",
        "\n",
        "#path = \n",
        "#net.load_state_dict(torch.load(path))\n",
        "\n",
        "\n",
        "def test_nn(model, device, test_loader):\n",
        "    '''\n",
        "    Test a model on a dataset (for validation/testing).\n",
        "    '''\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device).type(torch.get_default_dtype()), target.to(device)\n",
        "            data = data.reshape(data.shape[0], -1)\n",
        "\n",
        "            output = model(data)\n",
        "            test_loss += torch.nn.functional.cross_entropy(output, target, reduction=\"sum\").item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    return test_loss, correct / len(test_loader.dataset)\n",
        "\n",
        "print(\"Now testing the network, this will require a powerful gpu...\")\n",
        "test_loss, acc = test_nn(net, device, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "Sqt9esOm070u",
        "outputId": "e99afe01-2d69-4c57-bcc3-bdfab809e0a6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Now testing the network, this will require a powerful gpu...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5c78c87524a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Now testing the network, this will require a powerful gpu...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-5c78c87524a3>\u001b[0m in \u001b[0;36mtest_nn\u001b[0;34m(model, device, test_loader)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sum\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# sum up batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# get the index of the max log-probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-69bfc5dc4f62>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_layer_alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pilimit_lib/inf/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g_in, gbar_in, s_in)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgbar_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mg_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInfPiLinearReLUFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAmult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAmult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgbar_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pilimit_lib/inf/functional.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, g_in, A, Amult, B, A_pi, Amult_pi, B_pi, gbar_in, s_in, bias)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;31m# perform forward pass, return q for backwars storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mg_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minf_linear_forward_return_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAmult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgbar_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;31m# save everything\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pilimit_lib/inf/functional.py\u001b[0m in \u001b[0;36minf_linear_forward_return_q\u001b[0;34m(A, Amult, B, g, gbar, s, bias, bias_alpha)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# apply B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbar\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;31m# analogous \"activation\" of the inf-width net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The performance should be About 60.9%, which is slightly less than the best overall reported performance in our paper (61.5%). This is because we refactored the repository compared to our original results, so if you'd like to exactly reproduce our results, please use pilimit_orig. \n",
        "\n",
        "Let's quickly inspect this network:"
      ],
      "metadata": {
        "id": "J_cEj3cu2QlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for n, layer in enumerate(net.layers):\n",
        "  print(f\"Layer {n} A has shape {layer.A.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5g6wPzM2gM4",
        "outputId": "536eaaee-3131-4088-c12b-69e2c132cdf9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0 A has shape torch.Size([3072, 400])\n",
            "Layer 1 A has shape torch.Size([400, 400])\n",
            "Layer 2 A has shape torch.Size([400, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice a couple things **(layer shapes are only if the trained pi-net has been loaded)**:\n",
        "\n",
        "- 1 hidden layer does not include input/output for our network, so there are 3 layers total (named 0 through 2)\n",
        "- Layer 0 has an input of shape 3072 and layer 2 has output shape 10 \n",
        "- The other dimensions are of shape 50000*46=2300000, because this is the network from epoch 46 of training (out of 50) on 50000"
      ],
      "metadata": {
        "id": "o7rK2_014SH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling and testing a Finite Pi-Net"
      ],
      "metadata": {
        "id": "QT_CxwEmRe3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each layer class that we have defined has an associated ```sample()``` function which can be used to create a finite-layer equivalent. Under ```networks.py``` is defined a ```FinPiMLPSample```class, which demonstrates how to use this sample function along with the example infinite network.\n",
        "\n",
        "There are 2 important things to note here:\n",
        "- Unlike the infnet, finite layer classes do not include the activation built in (subject to refactor later)\n",
        "- When sampling a finite layer, it is necessary to pass in the previous layer's omega as per the paper's instructions for building a pi-net\n",
        "\n",
        "Be sure to fully understand how finite layers are sampled from infinite ones before creating a new finite-sampled network. \n",
        "\n",
        "There is also a big difference between the two following types of sampling:\n",
        "\n",
        "1. sampling from a *trained* infinite pi-net to create some finite network\n",
        "2. sampling from an *untrained* infinite pi-net, then training that network\n",
        "\n",
        "In the paper, we mostly refer to type #2 to demonstrate the difference in training an infinite or finite network from the same initialization. When sampling type #1 as we are about to show, we expect performance to heavily suffer as the network was trained in infinite-width (though performance would converge as width approaches infinity).\n"
      ],
      "metadata": {
        "id": "VqVB3n4IhDHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now, let's sample a finite network of width 2048 from the above loaded infnet. Note that the syntax to do so is incredibly light - only one line - and the same testing function defined above can be used!"
      ],
      "metadata": {
        "id": "YXcdH7Uyi8CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pilimit_lib.examples.networks import FinPiMLPSample\n",
        "\n",
        "mynet = FinPiMLPSample(net, 2048)\n",
        "print(\"Now testing the finite network...\")\n",
        "test_loss, acc = test_nn(net, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9Uncrhdinfi",
        "outputId": "5de6f86d-d373-41a9-99c7-3e431bb0dbeb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pilimit_lib/inf/layers.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.register_buffer(\"bias_alpha\", torch.tensor(bias_alpha, dtype=torch.get_default_dtype()))\n",
            "/usr/local/lib/python3.9/dist-packages/pilimit_lib/inf/layers.py:239: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.register_buffer(\"bias_alpha\", torch.tensor(bias_alpha, dtype=torch.get_default_dtype()))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now testing the finite network...\n",
            "\n",
            "Test set: Average loss: 23025.8512, Accuracy: 1000/10000 (10.00%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final notes"
      ],
      "metadata": {
        "id": "y80WkLsNRilM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For any future Pi-Nets we highly recommend using pilimit_lib as it is easier to read and modify. The results presented in our paper, however, come from pilimit_orig and due to minor issues like floating point conversions, results with pilimit_lib will be ever so slightly different.\n",
        "\n",
        "Therefore, we also include the original pilimit_orig in the repo along with some instructions on how to use it if one wishes exact reproduction.\n",
        "\n",
        "For best possible performance, we have an infinite pi-net of rank 400 already trained on CIFAR10 available in the repo."
      ],
      "metadata": {
        "id": "4MHyyHZWeyAK"
      }
    }
  ]
}